```Python
显卡

驱动

cuda --> 指令集

anaconda	环境管理软件

pytorch/tensorfolw
	两者区别，tensorflow历史更久，里边的API不是那么的平易近人，更难用，但是最新的版本更常用，这个在工业生产更常用
	pytorch比较新，更好用，这个在学术科研更常用

pycharm/jupyter notebook
	l
```

```Python
#
# To activate this environment, use
#
#     $ conda activate F:\AIandTools\Anaconda\DeepLearning
#
# To deactivate an active environment, use
#
#     $ conda deactivate
```

anaconda里的环境是指独立的工具

- 查看信息

    ```Python
    conda info
    ```




- 查看CUDA版本

    ```Python
    nvcc -V  以这个为准
    
    nvidia-smi  可能会显示包版本
    ```

- 检查CUDA是否可用

    ```Python
    import torch
    torch.cuda.is_available()   # TRUE
    ```

    


- 在anconda中创建一个指定路径的房间(环境)：

```Python
conda create --prefix=安装路径\环境名 python=3.7
```

- 查看所有的环境：

```Python

```

- 进入特定的环境

```
conda activate xxx		// xxx是环境名
```

- 退出当前环境回到大厅(base)

```
conda deactivate
```

- 删除特定的环境

```
conda remove -n 环境名 --all
```

- 添加特定的镜像源：

```
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro
conda config --add channels http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
```

- 查看当前环境下已经安装好的包/库的列表：

```
conda list 
```

- 查看当前设置的下载源：

```
conda config --show-source
```

- 移除某一镜像源

```
conda config --remove channels 源名称或链接 
```

- 设置检索路径

```
conda config --set show_channel_urls yes
```

<<<<<<< HEAD
# 数据基本操作

- 张量表示一个数值组成的数组，这个数组可能有多个维度

    ```Python
    x = torch.arange(12)
    x
    
    --> 
    tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
    ```

- 可以通过shape属性俩访问张量的形状和张量中元素的个数

    ```Python
    x.shape
    
    --> 
    torch.Size([12])
    
    x.numel()
    
    --> 
    12
    ```

- 改变张量的形状而不改变元素的数量和元素值，可以使用reshape函数

    ```Python
    x.reshape(3,4)
    
    -->
    tensor([[ 0,  1,  2,  3],
            [ 4,  5,  6,  7],
            [ 8,  9, 10, 11]])
    ```

- 使用全0，全1

    ```Python
    torch.zeros((2,3,4))	
    
    -->
    tensor([[[0., 0., 0., 0.],
             [0., 0., 0., 0.],
             [0., 0., 0., 0.]],
    
            [[0., 0., 0., 0.],
             [0., 0., 0., 0.],
             [0., 0., 0., 0.]]])
    
    torch.ones((2,3,4))
    
    -->
    tensor([[[1., 1., 1., 1.],
             [1., 1., 1., 1.],
             [1., 1., 1., 1.]],
    
            [[1., 1., 1., 1.],
             [1., 1., 1., 1.],
             [1., 1., 1., 1.]]])
    ```

- 通过提供包含数值的Python列表或嵌套列表来为所需张量的每个元素赋予确定值

    ```Python
    torch.tensor([[2,1,4,2],[1,2,3,4],[4,3,2,1]])
    
    -->
    tensor([[2, 1, 4, 2],
            [1, 2, 3, 4],
            [4, 3, 2, 1]])
    ```

- 对张量进行算术运算(+,-,*,/,**)，左右的运算都可以被升级为按元素运算

    ```Python
    x = torch.tensor([1.0,2,4,8])
    y = torch.tensor([2,2,2,2])
    x+y, x-y, x*y, x/y, x**y
    
    -->
    (tensor([ 3.,  4.,  6., 10.]),
     tensor([-1.,  0.,  2.,  6.]),
     tensor([ 2.,  4.,  8., 16.]),
     tensor([0.5000, 1.0000, 2.0000, 4.0000]),
     tensor([ 1.,  4., 16., 64.]))
    ```

- 按元素方式应用更多的计算

    ```Python
    torch.exp(x)
    
    -->
    tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])
    ```

- 将多个张量连结在一起

    ```Python
    X = torch.arange(12,dtype=torch.float32).reshape(3,4)
    Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])
    torch.cat((X,Y),dim=0),torch.cat((X,Y),dim=1)   # dim=0，按行合并； dim=1按列合并
    
    -->
    (tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.],
             [ 2.,  1.,  4.,  3.],
             [ 1.,  2.,  3.,  4.],
             [ 4.,  3.,  2.,  1.]]),
     tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
             [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
             [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))
    ```

- 对张量中所有元素进行求和会产生只有一个元素的张量

    ```Python
    X.sum()
    
    -->
    tensor(66.)
    ```

- 可以通过广播机制来执行按元素操作

    ```Python
    a = torch.arange(3).reshape((3,1))  #  a 是一个3*1的向量
    b = torch.arange(2).reshape((1,2))  #  b 是一个1*2的向量
    a,b
    
    -->
    (tensor([[0],
             [1],
             [2]]),
     tensor([[0, 1]]))
    
    
    a + b   # 把a在列上复制，复制成一个3*2的，把 b 在行上复制，复制成一个3*2的，然后再相加
    -->
    tensor([[0, 1],
            [1, 2],
            [2, 3]])
    ```



### 元素访问

- 可以用 -1 来选择最后一个元素，可以用 1:3 来选择第二个和第三个元素

    ```Python
    X, X[-1], X[1:3]
    
    -->
    (tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.]]),
     tensor([ 8.,  9., 10., 11.]),  # 最后一行
     tensor([[ 4.,  5.,  6.,  7.],  # 第二行和第三行，索引从0开始
             [ 8.,  9., 10., 11.]]))
    ```

- 为多个元素赋相同的值，只需要索引想要赋值的元素

    ```Python
    X
    -->
    tensor([[ 0.,  1.,  2.,  3.],
            [ 4.,  5.,  6.,  7.],
            [ 8.,  9., 10., 11.]])
            
    X[0:2, :] = 12
    X
    -->
    tensor([[12., 12., 12., 12.],
            [12., 12., 12., 12.],
            [ 8.,  9., 10., 11.]])
    ```

- 运行一些操作可能导致为新结果分配内存

    ```Python
    before = id(Y)    # id 类似于C语言中的指针，是Y在内存中的唯一标识号
    Y = Y + X
    id(Y) == before  # 操作后新的 id 和原来的 id 是不同的
    
    -->
    False
    ```

- 执行原地操作

    ```Python
    X = torch.arange(12,dtype=torch.float32).reshape(3,4)
    Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])
    Z = torch.zeros_like(Y)  # Z 的形状和数据类型和 Y 一样，但是所有的数据元素是 0
    print('id(Z): ', id(Z))
    Z[:] = X + Y
    print('id(Z): ', id(Z))
    
    --->
    id(Z):  2347331944912   # Z的内存没有发生变化
    id(Z):  2347331944912
    ```

- 如果在后续操作中没有重复使用X，可以使用X[:] = X + Y 或 X += Y 来减少操作的内存开销

    ```Python
    before = id(X)
    X += Y
    id(X) == before
    
    --->
    True
    ```

- 转化为NumPy张量

    ```Python
    A = X.numpy()
    B = torch.tensor(A)
    type(A), type(B)
    
    --->
    (numpy.ndarray, torch.Tensor)
    ```

- 将大小为1的张量准换为Python标量

    ```Python
    a = torch.tensor([3.5])
    a,a.item(),float(a),int(a)
    
    --->
    (tensor([3.5000]), 3.5, 3.5, 3)
    ```

    
----

# 数据预处理

- 创建一个人工数据集，并存储在一个CSV文件中

    ```Python
    import os
    
    os.makedirs(os.path.join('..','data'),exist_ok=True)
    data_file = os.path.join('..','data','house_tiny.csv')
    with open(data_file, 'w') as f:
        f.write('NumRooms,Alley,Price\n')  # 列名
        f.write('NA,Pave,127500\n')  #  每行表示一个数据样本
        f.write('2,NA,106000\n') 
        f.write('4,NA,178100\n')
        f.write('NA,NA,140000\n')
    ```

- 从创建的CSV文件中加载原始数据集

    ```Python
    # pip install pandas
    
    import pandas as pd
    
    data = pd.read_csv(data_file)
    print(data)
    
    -->
       NumRooms Alley   Price
    0       NaN  Pave  127500
    1       2.0   NaN  106000
    2       4.0   NaN  178100
    3       NaN   NaN  140000
    ```

- 处理一些缺失的数据：插值和删除，这里使用插值：

    ```Python
    inputs, outputs = data.iloc[:,0:2], data.iloc[:,2]
    inputs = inputs.fillna(inputs.mean())
    print(inputs)
    ```

- 对于ipnuts中的类别值或离散值，将NaN视为一个类别

    ```Python
    inputs = pd.get_dummies(inputs, dummy_na = True)
    print(inputs)
    
    -->
       NumRooms  Alley_Pave  Alley_nan
    0       3.0        True      False
    1       2.0       False       True
    2       4.0       False       True
    3       3.0       False       True
    ```

    

# 线性代数

- 标量由只有一个元素的张量表示

    ```Python
    import torch
    x = torch.tensor([3.0])
    y = torch.tensor([2.0])
    
    x + y, x * y, x / y, x**y
    ```

- 